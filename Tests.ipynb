{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fdc27d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pymongo import MongoClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c795d996",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pymongo import MongoClient\n",
        "\n",
        "# Connect to the MongoDB server\n",
        "client = MongoClient(\"mongodb+srv://IRGC_NEW:iran135@cluster0.6ycjkak.mongodb.net/\")\n",
        "\n",
        "# Select the database and collection\n",
        "db = client[\"IranMalDB\"]\n",
        "tweets_collection = db[\"tweets\"]\n",
        "\n",
        "# Perform the aggregation\n",
        "pipeline = [\n",
        "    {\"$sort\": {\"CreateDate\": 1}},\n",
        "    {\"$skip\": 100 * 1},\n",
        "    {\"$limit\": 100}\n",
        "]\n",
        "\n",
        "results = list(tweets_collection.aggregate(pipeline))\n",
        "\n",
        "# Print the results\n",
        "for result in  [result for result in results if result['Antisemitic'] ==1 ]:\n",
        "    print(result)\n",
        "\n",
        "# Close the connection\n",
        "client.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2848580",
      "metadata": {},
      "outputs": [],
      "source": [
        "from kafka import KafkaAdminClient\n",
        "\n",
        "admin = KafkaAdminClient(bootstrap_servers=\"localhost:9092\")\n",
        "topics = admin.list_topics()\n",
        "print(topics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20551f14",
      "metadata": {},
      "source": [
        "הסרת סימני פיסוק\n",
        "הסרת סימנים מיוחדים \n",
        "הסרת תווים לבנים מיותרים (טאבים, רצף רווחים ארוך, סימני סוף שורה לסוגיהם).\n",
        "הסרת stop words \n",
        "הפיכת הטקסט לאותיות קטנות \n",
        "למטיזציה (מציאת שורשים)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab1aba43",
      "metadata": {},
      "outputs": [],
      "source": [
        "import string\n",
        "string.punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c677f3b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "translator = str.maketrans('', '', string.punctuation)\n",
        "no_punct = text.translate(translator)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "008499e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Sample text\n",
        "text = \"This is a sample sentence showing stopword removal.\"\n",
        "\n",
        "# Get English stopwords and tokenize\n",
        "stop_words = set(stopwords.words('english'))\n",
        "tokens = word_tokenize(text.lower())\n",
        "\n",
        "# Remove stopwords\n",
        "# filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "# print(\"Original:\", tokens)\n",
        "# print(\"Filtered:\", filtered_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db39c5ea",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dc68ac7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "import os\n",
        "\n",
        "nltk_data_path = os.path.join(os.path.dirname(__file__), \"nltk_data\")\n",
        "\n",
        "\n",
        "nltk.download('punkt', download_dir=nltk_data_path)\n",
        "nltk.download('stopwords', download_dir=nltk_data_path)\n",
        "\n",
        "nltk.data.path.append(nltk_data_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4497b4f6",
      "metadata": {},
      "source": [
        "מציאת הרגש של הטקסט - חיובי, שלילי או ניטראלי. (בהתאם לתרגיל קודם)\n",
        "מציאת שמות של כלי נשק על פי רשימה שחורה. במידה ויש כלי נשק יש להוסיף שדה מערך הכולל את כלי הנשק שנמצאו. (שימו לב גם כלי הנשק אמורים לעבור תהליכי עיבוד בדומה לטקסטים)\n",
        "מציאת חתימת הזמן העדכנית ביותר בתוך התוכן של הטקסט (תאריך), אם קיימת - יש להוסיף לשדה את הערך שנמצא, במידה ויש יותר מאחד יש לשמור את הכי מאוחר.\n",
        "\n",
        "\n",
        "sentiment = ?\n",
        "weapons_detected = []\n",
        "relevant_timestamp = “25/03/2020” or \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89e9d59b",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.13.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
